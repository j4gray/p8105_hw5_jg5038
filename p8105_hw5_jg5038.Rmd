---
title: "p8105_hw5_jg5038"
author: "Julia Gray"
date: "2025-11-05"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)

#these options were messing up my fig.height 
#knitr::opts_chunk$set(
#  fig.width = 6,
#  fig.asp = .6
#)

knitr::opts_chunk$set(
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Problem 1: Birthday problem

```{r}
#define data generating mechanism
birthdays = sample(1:365, 5, replace = TRUE)

#run the analysis
repeated_bday = length(unique(birthdays)) < 5

#return the result
repeated_bday
```


put this in a function

```{r}
bday_sim = function(n_room) {
  
  birthdays = sample(1:365, n_room, replace = TRUE)

  repeated_bday = length(unique(birthdays)) < n_room

  repeated_bday
}

#bday_sim(20)
```

```{r}
bday_sim_results = 
  expand_grid(
    bdays = 5:50,
    iter = 1:1000
  ) |> 
  mutate(
    result = map_lgl(bdays, bday_sim)
  ) |> 
  group_by (
    bdays
  ) |> 
  summarize(
    prob_repeat = mean(result)
  )
```

Plot results (test):

```{r}
bday_sim_results |> 
  ggplot(aes(x = bdays, y = prob_repeat)) +
  geom_point() +
  geom_line() +
  geom_hline(yintercept = 0.5, color = "orange") +
  labs(
    title = "Probability of 2+ People Sharing a Birthday based on Group Size",
    x = "Group Size",
    y = "Probability"
  )
```

### Problem 2
Problem 2 = if you're study is underpowered, you're going to overestimate effect size. If only see significant results = not getting idea of what real value is

```{r}
#set model params
n = 30
sigma = 5
mu = 0

n_trials = 5000
alpha = 0.05

#create simulation function
norm_dist_sim_fn = function (mu = 0, n = 30, sigma = 5, alpha = 0.05) {
  
  #generate data
  norm_vec = rnorm(n = n, mean = mu, sd = sigma)
  
  #run ttest and return estimate & p.value
  t.test(norm_vec, mu = 0, conf.level = 1-alpha) |> 
    broom::tidy() |> 
    select(estimate, p.value)
}
```

Run for mu = 0
```{r}
#test = norm_dist_sim_fn(mu=mu)

#run for mu = 0
norm_sim_results_0 = 
  expand_grid(
    mean = mu,
    iter = 1:n_trials
  ) |> 
  mutate(
    t_results = map(mean, norm_dist_sim_fn)
  ) |> 
  unnest(t_results)

#run for mu in {1, 2, 3, 4, 5, 6}
norm_sim_results = 
  expand_grid(
    mean = 1:6,
    iter = 1:n_trials
  ) |> 
  mutate(
    t_results = map(mean, norm_dist_sim_fn)
  ) |> 
  unnest(t_results)
```

Plot the results:

```{r}
norm_sim_results |> 
  group_by(mean) |> 
  summarize(
    power = sum(p.value < alpha) /  n()
  ) |> 
  ggplot(aes(x = mean, y = power)) +
  geom_point() +
  geom_line() +
  labs(
    title = "Effect Size Vs. Power",
    x = "Effect Size (true mean)",
    y = "Power"
  )
```

Comment:

Make a plot showing the average estimate of ðœ‡Ì‚ on the y axis and the true value of ðœ‡ on the x axis. Make a second plot (or overlay on the first) the average estimate of ðœ‡Ì‚  only in samples for which the null was rejected on the y axis and the true value of ðœ‡ on the x axis. Is the sample average of ðœ‡Ì‚ across tests for which the null is rejected approximately equal to the true value of ðœ‡
? Why or why not?

```{r}
avg_estimates = norm_sim_results |> 
  mutate(
    null_reject = (p.value < 0.05)
  )

all_sample_avg_estimates = avg_estimates |> 
  group_by(mean) |> 
  summarize(avg_estimate = mean(estimate), n = n()) |> 
  mutate(sample = 'all')

null_reject_avg_estimates = avg_estimates |> 
  filter(null_reject == TRUE) |> 
  group_by(mean) |> 
  summarize(avg_estimate = mean(estimate), n = n()) |> 
  mutate(sample = 'null_reject')

rbind(all_sample_avg_estimates, null_reject_avg_estimates) |> 
  ggplot(aes(x = mean, y = avg_estimate, color = sample)) + 
  geom_point() + 
  labs(
    color = "Source of Average Estimate",
    x = "True Mean",
    y = "Average Estimate"
  )
```

### Problem 3

```{r}
homicide_df = read.csv("https://raw.githubusercontent.com/washingtonpost/data-homicides/master/homicide-data.csv") |> 
  janitor::clean_names() |> 
  mutate(
    reported_date = as.Date(as.character(reported_date), format = "%y%m%d"),
    city_state = paste(city, state, sep=", ")
  )
```

The Washington Post dataset on homicides contains `r dim(homicide_df)[1]` observations. Each observation is a homicide and contains columns for `r colnames(homicide_df)`. 

```{r}
homicide_df |> 
  filter(disposition %in% c("Closed without arrest", "Open/No arrest")) |> 
  group_by(city_state) |> 
  summarize(unsolved_homicides = n()) |> 
  knitr::kable()
```

Prop test for Baltimore:

```{r}
prop_test_baltimore = 
  homicide_df |> 
  filter(city_state == "Baltimore, MD") |> 
  summarize(
    n_unsolved = sum(disposition %in% c("Closed without arrest", "Open/No arrest")),
    n_total = n()
  ) |> 
  with(prop.test(x = n_unsolved, n = n_total))

prop_test_baltimore |> 
  broom::tidy() |> 
  select(estimate, conf.low, conf.high) |> 
  knitr::kable()
```

Prop test for all cities:








